1.权值调整函数
kohonen算法：墨西哥草帽函数：获胜神经元对临近神经元的影响应该是由远及近的，由兴奋转为抑制，
大礼帽函数：是墨西哥草帽函数的一种简化
厨师帽函数：是大礼帽函数的一种简化

2.优胜邻域
获胜神经元为中心设定邻域半径R，该半径圈定的范围称为优胜邻域，优胜邻域内的所有神经元均按其离开
获胜神经元的距离远近不同程度地调整权值。 优胜邻域开始定得很大，但其大小随着训练次数的增加不断
收缩，最终收缩到半径为零

3.学习率
随着时间（离散的训练迭代次数）变长，学习率逐渐降低；随着拓扑距离的增大，学习率降低。
学习率函数的形式一般可以写成这样：η(t,N)=η(t)e−N，其中η(t)可采用t的单调下降函数也称退火函数，

4.输出层设计
输出层神经元数量设定和训练集样本的类别数相关，但是实际中我们往往不能清除地知道有多少类。
如果神经元节点数少于类别数，则不足以区分全部模式，训练的结果势必将相近的模式类合并为一类；
相反，如果神经元节点数多于类别数，则有可能分的过细，或者是出现“死节点”，即在训练过程中，
某个节点从未获胜过且远离其他获胜节点，因此它们的权值从未得到过更新。

不过一般来说，如果对类别数没有确定知识，宁可先设定较多的节点数，以便较好的映射样本的拓扑结构，
如果分类过细再酌情减少输出节点。“死节点”问题一般可通过重新初始化权值得到解决。

5.权值初始化问题
基本原则是尽量使权值的初始位置与输入样本的大概分布区域充分重合，不要出现大量的初始“死节点”。

一种简单易行的方法是从训练集中随机抽取m个输入样本作为初始权值
另一种可行的办法是先计算出全体样本的中心向量，在该中心向量基础上迭加小随机数作为权向量初始值，
也可将权向量的初始位置确定在样本群中（找离中心近的点）。

6.优胜邻域的设计
优胜领域设计原则是使领域不断缩小，这样输出平面上相邻神经元对应的权向量之间既有区别又有相当的相似性，
从而保证当获胜节点对某一类模式产生最大响应时，其领域节点也能产生较大响应。领域的形状可以是正方形、
六边形或者菱形。优势领域的大小用领域的半径表示，r(t)的设计目前没有一般化的数学方法，通常凭借经验来选择。
下面是两种典型形式：

r(t)=C1(1−tT)r(t)=C1e−B1t/T

C1为于输出层节点数有关的正常数，B1为大于1的常数，T为预先选定的最大训练次数。

7.学习率的设计
在训练开始时，学习率可以选取较大的值，之后以较快的速度下降，这样有利于很快捕捉到输入向量的大致结构，
然后学习率在较小的值上缓降至0值，这样可以精细地调整权值使之符合输入空间的样本分布结构。
在上一篇中，我们提到最终的学习率是由学习率*优胜领域的影响，也有一些资料是把两者分开的，
学习率就是一个递减的函数（学习率可以参考上面优胜邻域半径的设定形式，可选形式类似），
而优胜邻域也是t的递减函数，只不过我们队优胜邻域内的点进行更新罢了。
